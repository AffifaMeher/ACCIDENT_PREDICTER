{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Gender  Speed_of_Impact Helmet_Used Seatbelt_Used  Survived\n",
      "0   56  Female             27.0          No            No         1\n",
      "1   69  Female             46.0          No           Yes         1\n",
      "2   46    Male             46.0         Yes           Yes         0\n",
      "3   32    Male            117.0          No           Yes         0\n",
      "4   60  Female             40.0         Yes           Yes         0\n",
      "Accuracy: 55.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Use the absolute path to your dataset\n",
    "data = pd.read_csv(\"C:/Users/HP/Desktop/Accident_prediction/dataset/accident_data.csv\")\n",
    "\n",
    "# Proceed with your data preprocessing and model training\n",
    "print(data.head())  # Just to verify that the file loads correctly\n",
    "# Load your dataset\n",
    "# Load your dataset with the correct path\n",
    "#data = pd.read_csv(\"C:\\Users\\HP\\Desktop\\Accident_prediction\\dataset\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "data['Gender'] = le.fit_transform(data['Gender'])\n",
    "data['Helmet_Used'] = le.fit_transform(data['Helmet_Used'])\n",
    "data['Seatbelt_Used'] = le.fit_transform(data['Seatbelt_Used'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data[['Age', 'Gender', 'Speed_of_Impact', 'Helmet_Used', 'Seatbelt_Used']]\n",
    "y = data['Survived']\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create an imputer object with a strategy to fill missing values\n",
    "imputer = SimpleImputer(strategy='mean')  # You can change 'mean' to 'median', 'most_frequent', etc.\n",
    "\n",
    "# Apply the imputer to your feature set\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create an imputer object with a strategy to fill missing values\n",
    "imputer = SimpleImputer(strategy='mean')  # You can change 'mean' to 'median', 'most_frequent', etc.\n",
    "\n",
    "# Apply the imputer to your feature set\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the trained model using pickle\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
